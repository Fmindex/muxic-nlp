{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend ok\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pythainlp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-374f90710783>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Backend ok\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpythainlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpythainlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthai2vec\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pythainlp'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import keras\n",
    "import keras.backend\n",
    "if keras.backend.backend() != 'tensorflow':\n",
    "    raise BaseException(\"This script uses other backend\")\n",
    "else:\n",
    "    keras.backend.set_image_dim_ordering('th')\n",
    "    print(\"Backend ok\")\n",
    "\n",
    "from pythainlp.tokenize import word_tokenize\n",
    "from pythainlp.word_vector.thai2vec import get_model\n",
    "from numpy import zeros, array\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from pandas import read_csv\n",
    "from re import compile\n",
    "import pickle\n",
    "\n",
    "word2vec = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean(sentence):\n",
    "    return sentence.strip()\n",
    "\n",
    "def remove_tags(sentence):\n",
    "    regex = compile(r'<\\/?[\\w-]+>')\n",
    "    return regex.sub('', sentence)\n",
    "\n",
    "def remove_dash(sentence):\n",
    "    regex = compile(r'-')\n",
    "    return regex.sub('', sentence)\n",
    "\n",
    "def get_word2idx(tokenized_sentences):\n",
    "    word2idx ={}\n",
    "    for sentence in tokenized_sentences:\n",
    "        for word in sentence:\n",
    "            if word not in word2idx:\n",
    "                word2idx[word] = len(word2idx) + 1\n",
    "    word2idx['UNK'] = len(word2idx)\n",
    "    return word2idx\n",
    "\n",
    "def get_index(word, word2idx):\n",
    "    return word2idx[word] if word in word2idx else word2idx['UNK']\n",
    "\n",
    "def get_embeddings(word2vec, word2idx, dim=300):\n",
    "    embeddings = zeros((len(word2idx), dim))\n",
    "    for (word, i) in word2idx.items():\n",
    "        if word != 'UNK' and word in word2vec.index2word:\n",
    "            embeddings[i] = word2vec.word_vec(word)\n",
    "        else:\n",
    "            pass\n",
    "    return embeddings\n",
    "\n",
    "def get_training_data(tokenized_sentences, classes, classes2, word2idx, maxlen=1000, class_num=4, class_num_two=4):\n",
    "    train_x = array([[get_index(word, word2idx) for word in sentence] for sentence in tokenized_sentences])\n",
    "    train_y = [cls for cls in classes]\n",
    "    train_z = [cls for cls in classes2]\n",
    "\n",
    "    train_x = pad_sequences(train_x, maxlen=maxlen, dtype='int32', padding='post', truncating='pre', value=0.)\n",
    "    train_y = array([[1 if i == cls else 0 for i in range(0, class_num)] for cls in train_y])\n",
    "    train_z = array([[1 if i == cls else 0 for i in range(0, class_num_two)] for cls in train_z])\n",
    "\n",
    "    return (train_x, train_y, train_z)\n",
    "\n",
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as output:\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_object(filename):\n",
    "    r = {}\n",
    "    with open(filename, 'rb') as f:\n",
    "        r = pickle.load(f)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mood = []\n",
    "genre = []\n",
    "\n",
    "def get_corpus(path):\n",
    "    global mood, genre\n",
    "    corpus = read_csv(path)\n",
    "    corpus = corpus[['sentence', 'mood', 'genre']]\n",
    "    corpus['sentence'] = corpus['sentence'].apply(clean).apply(remove_tags)\n",
    "    corpus['tokenized_sentence'] = corpus['sentence'].apply(word_tokenize, engine='deepcut')\n",
    "    corpus['genre'] = corpus['genre'].apply(remove_dash)\n",
    "    mood += list(corpus.mood.unique())\n",
    "    genre += list(corpus.genre.unique())\n",
    "    return corpus\n",
    "    \n",
    "train_corpus = get_corpus('Train-NLP-Corpus.csv')\n",
    "test_corpus = get_corpus('Test-NLP-Corpus.csv')\n",
    "corpus = get_corpus('NLP-Corpus.csv')\n",
    "\n",
    "mood = sorted(list(set(mood)), reverse=True)\n",
    "genre = sorted(list(set(genre)), reverse=True)\n",
    "mood2idx = dict(zip(mood, [i for i in range(len(mood))]))\n",
    "genre2idx = dict(zip(genre, [i for i in range(len(genre))]))\n",
    "\n",
    "def pos_process(corpus):\n",
    "    global mood2idx, genre2idx\n",
    "    corpus['genre'] = corpus['genre'].apply(lambda x: genre2idx[x])\n",
    "    corpus['mood'] = corpus['mood'].apply(lambda x: mood2idx[x])\n",
    "    return corpus\n",
    "\n",
    "train_corpus = pos_process(train_corpus)\n",
    "test_corpus = pos_process(test_corpus)\n",
    "corpus = pos_process(corpus)\n",
    "\n",
    "print(mood, genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(test_corpus)\n",
    "display(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2idx = get_word2idx(corpus['tokenized_sentence'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'save_object' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3fe4f9f6f123>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Use in development only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msave_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'models/word2idx.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mword2idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models/word2idx.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'save_object' is not defined"
     ]
    }
   ],
   "source": [
    "#Use in development only\n",
    "save_object(word2idx, 'models/word2idx.pkl')\n",
    "word2idx = load_object('models/word2idx.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings = get_embeddings(word2vec, word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_x, train_y, train_z = get_training_data(train_corpus['tokenized_sentence'].values, train_corpus['mood'].values, train_corpus['genre'].values, word2idx)\n",
    "train_x, train_y, train_z = get_training_data(corpus['tokenized_sentence'].values, corpus['mood'].values, corpus['genre'].values, word2idx)\n",
    "test_x, test_y, test_z = get_training_data(test_corpus['tokenized_sentence'].values, test_corpus['mood'].values, test_corpus['genre'].values, word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 1000) (26, 4) (26, 4)\n",
      "(5, 1000) (5, 4) (5, 4)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape, train_y.shape, train_z.shape)\n",
    "print(test_x.shape, test_y.shape, test_z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, Conv1D, GlobalMaxPooling1D, Dropout, Dense, concatenate\n",
    "from keras.regularizers import l2\n",
    "from keras.constraints import max_norm\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "def get_classification_model(input_size, vocab_size, embeddings, embedding_dimension=300, class_num=4, class_num_two=4):\n",
    "    inp = Input(shape=(input_size,))\n",
    "    x = Embedding(vocab_size, embedding_dimension, weights=[embeddings], trainable=True)(inp)\n",
    "\n",
    "    convs = []\n",
    "    kernel_sizes = [3,4,5]\n",
    "    for kernel_size in kernel_sizes:\n",
    "        conv = Conv1D(100, kernel_size, activation='relu')(x)\n",
    "        pool = GlobalMaxPooling1D()(conv)\n",
    "        convs.append(pool)\n",
    "    \n",
    "    x = concatenate(convs)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(100, activation='relu', kernel_regularizer=l2(0.01), kernel_constraint=max_norm(3))(x)\n",
    "    out = Dense(class_num, activation='softmax', name='mood')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(100, activation='relu', kernel_regularizer=l2(0.01), kernel_constraint=max_norm(3))(x)\n",
    "    aux_out = Dense(class_num_two, activation='softmax', name='genre')(x)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=[out, aux_out])\n",
    "    model.summary()\n",
    "    model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['categorical_accuracy'], loss_weights=[1., 0.2])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1000, 300)    25500       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 998, 100)     90100       embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 997, 100)     120100      embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 996, 100)     150100      embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 100)          0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 100)          0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 100)          0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 300)          0           global_max_pooling1d_1[0][0]     \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "                                                                 global_max_pooling1d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 300)          0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 100)          30100       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 100)          0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 100)          10100       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "mood (Dense)                    (None, 4)            404         dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "genre (Dense)                   (None, 4)            404         dense_16[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 426,808\n",
      "Trainable params: 426,808\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "music_model = get_classification_model(train_x.shape[1], len(word2idx), embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26 samples, validate on 5 samples\n",
      "Epoch 1/10\n",
      "26/26 [==============================] - 2s 68ms/step - loss: 3.9253 - mood_loss: 1.2458 - genre_loss: 0.8789 - mood_categorical_accuracy: 0.2308 - genre_categorical_accuracy: 0.2692 - val_loss: 3.6744 - val_mood_loss: 1.0482 - val_genre_loss: 0.7171 - val_mood_categorical_accuracy: 0.2000 - val_genre_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00001: val_mood_categorical_accuracy improved from -inf to 0.20000, saving model to models/music_weights.h5\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 3.6781 - mood_loss: 1.0362 - genre_loss: 0.7961 - mood_categorical_accuracy: 0.2308 - genre_categorical_accuracy: 0.3077 - val_loss: 3.5235 - val_mood_loss: 0.9303 - val_genre_loss: 0.6567 - val_mood_categorical_accuracy: 0.4000 - val_genre_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00002: val_mood_categorical_accuracy improved from 0.20000 to 0.40000, saving model to models/music_weights.h5\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 1s 56ms/step - loss: 3.5378 - mood_loss: 0.8804 - genre_loss: 0.9776 - mood_categorical_accuracy: 0.4231 - genre_categorical_accuracy: 0.3077 - val_loss: 3.3526 - val_mood_loss: 0.7899 - val_genre_loss: 0.6079 - val_mood_categorical_accuracy: 0.6000 - val_genre_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00003: val_mood_categorical_accuracy improved from 0.40000 to 0.60000, saving model to models/music_weights.h5\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 1s 57ms/step - loss: 3.4051 - mood_loss: 0.7780 - genre_loss: 0.9298 - mood_categorical_accuracy: 0.5769 - genre_categorical_accuracy: 0.3077 - val_loss: 3.2401 - val_mood_loss: 0.7026 - val_genre_loss: 0.5846 - val_mood_categorical_accuracy: 0.8000 - val_genre_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00004: val_mood_categorical_accuracy improved from 0.60000 to 0.80000, saving model to models/music_weights.h5\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 1s 56ms/step - loss: 3.2738 - mood_loss: 0.6697 - genre_loss: 0.9176 - mood_categorical_accuracy: 0.6154 - genre_categorical_accuracy: 0.3846 - val_loss: 3.1592 - val_mood_loss: 0.6470 - val_genre_loss: 0.5568 - val_mood_categorical_accuracy: 0.8000 - val_genre_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00005: val_mood_categorical_accuracy did not improve\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 1s 56ms/step - loss: 2.9832 - mood_loss: 0.4619 - genre_loss: 0.6023 - mood_categorical_accuracy: 0.6923 - genre_categorical_accuracy: 0.4615 - val_loss: 3.0545 - val_mood_loss: 0.5679 - val_genre_loss: 0.5332 - val_mood_categorical_accuracy: 0.8000 - val_genre_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00006: val_mood_categorical_accuracy did not improve\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 1s 56ms/step - loss: 2.9937 - mood_loss: 0.4618 - genre_loss: 0.7591 - mood_categorical_accuracy: 0.5769 - genre_categorical_accuracy: 0.4231 - val_loss: 2.9226 - val_mood_loss: 0.4618 - val_genre_loss: 0.5084 - val_mood_categorical_accuracy: 0.6000 - val_genre_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00007: val_mood_categorical_accuracy did not improve\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 1s 56ms/step - loss: 2.8213 - mood_loss: 0.3172 - genre_loss: 0.7247 - mood_categorical_accuracy: 0.7692 - genre_categorical_accuracy: 0.3846 - val_loss: 2.7955 - val_mood_loss: 0.3603 - val_genre_loss: 0.4853 - val_mood_categorical_accuracy: 0.6000 - val_genre_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00008: val_mood_categorical_accuracy did not improve\n",
      "Epoch 9/10\n",
      "26/26 [==============================] - 1s 56ms/step - loss: 2.8088 - mood_loss: 0.3314 - genre_loss: 0.6963 - mood_categorical_accuracy: 0.7308 - genre_categorical_accuracy: 0.4231 - val_loss: 2.6920 - val_mood_loss: 0.2825 - val_genre_loss: 0.4608 - val_mood_categorical_accuracy: 0.6000 - val_genre_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00009: val_mood_categorical_accuracy did not improve\n",
      "Epoch 10/10\n",
      "26/26 [==============================] - 1s 57ms/step - loss: 2.8010 - mood_loss: 0.3234 - genre_loss: 0.8015 - mood_categorical_accuracy: 0.6538 - genre_categorical_accuracy: 0.4615 - val_loss: 2.5957 - val_mood_loss: 0.2120 - val_genre_loss: 0.4351 - val_mood_categorical_accuracy: 0.8000 - val_genre_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00010: val_mood_categorical_accuracy did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7ea4f0bc50>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_path = 'models/music_weights.h5'\n",
    "\n",
    "callbacks_list_model = [\n",
    "    ModelCheckpoint(\n",
    "        weight_path,\n",
    "        monitor = \"val_mood_categorical_accuracy\",\n",
    "        mode = 'max',\n",
    "        verbose = 1,\n",
    "        save_best_only = True,\n",
    "        save_weights_only = True,\n",
    "    )   \n",
    "]\n",
    "\n",
    "music_model.fit(train_x, [train_y, train_z], batch_size=128, epochs=10, verbose=1, validation_data=(test_x, [test_y, test_z]), callbacks=callbacks_list_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "music_model.load_weights(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from numpy import apply_along_axis\n",
    "\n",
    "def prob2class(probs):\n",
    "    return apply_along_axis(lambda x: max(enumerate(x), key=itemgetter(1))[0], 1, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_y, pred_z = music_model.predict(test_x)\n",
    "class_y = prob2class(test_y)\n",
    "class_z = prob2class(test_z)\n",
    "pred_y = prob2class(pred_y)\n",
    "pred_z = prob2class(pred_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 1, 2, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([3, 0, 1, 1, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([2, 0, 3, 2, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(class_y)\n",
    "display(pred_y)\n",
    "\n",
    "display(class_z)\n",
    "display(pred_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/image-data/image-conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/image-data/image-conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/image-data/image-conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/image-data/image-conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.26666666666666666, 0.8, 0.25, 0.3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.05714285714285715, 0.4, 0.04, 0.1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "def evaluate(test_y, pred_y, labels=[i for i in range(0,10)]):\n",
    "    f1 = f1_score(test_y, pred_y, average='macro', labels=labels)\n",
    "    accuracy = accuracy_score(test_y, pred_y)\n",
    "    precision = precision_score(test_y, pred_y, average='macro', labels=labels)\n",
    "    recall = recall_score(test_y, pred_y, average='macro', labels=labels)\n",
    "    return f1, accuracy, precision, recall\n",
    "\n",
    "display(evaluate(class_y, pred_y))\n",
    "display(evaluate(class_z, pred_z))\n",
    "# display(*((class2name(cls), class2name(pred)) for cls, pred in zip(class_y, pred_y) if cls != pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
